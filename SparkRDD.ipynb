{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03b904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"TestingRDDS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e02e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12973724",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = \"\"\"PySpark has been released in order \n",
    "to support the collaboration of Apache Spark and Python, \n",
    "it actually is a Python API for Spark. In addition, PySpark, \n",
    "helps you interface with Resilient Distributed Datasets (RDDs) \n",
    "in Apache Spark and Python programming language.\"\"\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e6d6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PySpark',\n",
       " 'has',\n",
       " 'been',\n",
       " 'released',\n",
       " 'in',\n",
       " 'order',\n",
       " '\\nto',\n",
       " 'support',\n",
       " 'the',\n",
       " 'collaboration',\n",
       " 'of',\n",
       " 'Apache',\n",
       " 'Spark',\n",
       " 'and',\n",
       " 'Python,',\n",
       " '\\nit',\n",
       " 'actually',\n",
       " 'is',\n",
       " 'a',\n",
       " 'Python',\n",
       " 'API',\n",
       " 'for',\n",
       " 'Spark.',\n",
       " 'In',\n",
       " 'addition,',\n",
       " 'PySpark,',\n",
       " '\\nhelps',\n",
       " 'you',\n",
       " 'interface',\n",
       " 'with',\n",
       " 'Resilient',\n",
       " 'Distributed',\n",
       " 'Datasets',\n",
       " '(RDDs)',\n",
       " '\\nin',\n",
       " 'Apache',\n",
       " 'Spark',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'programming',\n",
       " 'language.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab1a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rdd = spark.sparkContext.parallelize(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f8625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_data = word_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c6bc1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PySpark',\n",
       " 'has',\n",
       " 'been',\n",
       " 'released',\n",
       " 'in',\n",
       " 'order',\n",
       " '\\nto',\n",
       " 'support',\n",
       " 'the',\n",
       " 'collaboration',\n",
       " 'of',\n",
       " 'Apache',\n",
       " 'Spark',\n",
       " 'and',\n",
       " 'Python,',\n",
       " '\\nit',\n",
       " 'actually',\n",
       " 'is',\n",
       " 'a',\n",
       " 'Python',\n",
       " 'API',\n",
       " 'for',\n",
       " 'Spark.',\n",
       " 'In',\n",
       " 'addition,',\n",
       " 'PySpark,',\n",
       " '\\nhelps',\n",
       " 'you',\n",
       " 'interface',\n",
       " 'with',\n",
       " 'Resilient',\n",
       " 'Distributed',\n",
       " 'Datasets',\n",
       " '(RDDs)',\n",
       " '\\nin',\n",
       " 'Apache',\n",
       " 'Spark',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'programming',\n",
       " 'language.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401eb566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "183aab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1237e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordStartsWith(word,letter):\n",
    "    return word.startswith(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81349fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'Spark.', 'Spark']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.filter(lambda x: wordStartsWith(x,\"S\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b11adc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PySparkPySpark',\n",
       " 'hashas',\n",
       " 'beenbeen',\n",
       " 'releasedreleased',\n",
       " 'inin',\n",
       " 'orderorder',\n",
       " '\\nto\\nto',\n",
       " 'supportsupport',\n",
       " 'thethe',\n",
       " 'collaborationcollaboration',\n",
       " 'ofof',\n",
       " 'ApacheApache',\n",
       " 'SparkSpark',\n",
       " 'andand',\n",
       " 'Python,Python,',\n",
       " '\\nit\\nit',\n",
       " 'actuallyactually',\n",
       " 'isis',\n",
       " 'aa',\n",
       " 'PythonPython',\n",
       " 'APIAPI',\n",
       " 'forfor',\n",
       " 'Spark.Spark.',\n",
       " 'InIn',\n",
       " 'addition,addition,',\n",
       " 'PySpark,PySpark,',\n",
       " '\\nhelps\\nhelps',\n",
       " 'youyou',\n",
       " 'interfaceinterface',\n",
       " 'withwith',\n",
       " 'ResilientResilient',\n",
       " 'DistributedDistributed',\n",
       " 'DatasetsDatasets',\n",
       " '(RDDs)(RDDs)',\n",
       " '\\nin\\nin',\n",
       " 'ApacheApache',\n",
       " 'SparkSpark',\n",
       " 'andand',\n",
       " 'PythonPython',\n",
       " 'programmingprogramming',\n",
       " 'language.language.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.map(lambda x:x+x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac914030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'PySpark'),\n",
       " (1, 'has'),\n",
       " (2, 'been'),\n",
       " (3, 'released'),\n",
       " (4, 'in'),\n",
       " (5, 'order'),\n",
       " (6, '\\nto'),\n",
       " (7, 'support'),\n",
       " (8, 'the'),\n",
       " (9, 'collaboration'),\n",
       " (10, 'of'),\n",
       " (11, 'Apache'),\n",
       " (12, 'Spark'),\n",
       " (13, 'and'),\n",
       " (14, 'Python,'),\n",
       " (15, '\\nit'),\n",
       " (16, 'actually'),\n",
       " (17, 'is'),\n",
       " (18, 'a'),\n",
       " (19, 'Python'),\n",
       " (20, 'API'),\n",
       " (21, 'for'),\n",
       " (22, 'Spark.'),\n",
       " (23, 'In'),\n",
       " (24, 'addition,'),\n",
       " (25, 'PySpark,'),\n",
       " (26, '\\nhelps'),\n",
       " (27, 'you'),\n",
       " (28, 'interface'),\n",
       " (29, 'with'),\n",
       " (30, 'Resilient'),\n",
       " (31, 'Distributed'),\n",
       " (32, 'Datasets'),\n",
       " (33, '(RDDs)'),\n",
       " (34, '\\nin'),\n",
       " (35, 'Apache'),\n",
       " (36, 'Spark'),\n",
       " (37, 'and'),\n",
       " (38, 'Python'),\n",
       " (39, 'programming'),\n",
       " (40, 'language.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = word_rdd.collect()\n",
    "word_list_ord = [(i,x) for i,x in enumerate(word_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d1bfae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(40, 'language.'),\n",
       " (39, 'programming'),\n",
       " (38, 'Python'),\n",
       " (37, 'and'),\n",
       " (36, 'Spark'),\n",
       " (35, 'Apache'),\n",
       " (34, '\\nin'),\n",
       " (33, '(RDDs)'),\n",
       " (32, 'Datasets'),\n",
       " (31, 'Distributed'),\n",
       " (30, 'Resilient'),\n",
       " (29, 'with'),\n",
       " (28, 'interface'),\n",
       " (27, 'you'),\n",
       " (26, '\\nhelps'),\n",
       " (25, 'PySpark,'),\n",
       " (24, 'addition,'),\n",
       " (23, 'In'),\n",
       " (22, 'Spark.'),\n",
       " (21, 'for'),\n",
       " (20, 'API'),\n",
       " (19, 'Python'),\n",
       " (18, 'a'),\n",
       " (17, 'is'),\n",
       " (16, 'actually'),\n",
       " (15, '\\nit'),\n",
       " (14, 'Python,'),\n",
       " (13, 'and'),\n",
       " (12, 'Spark'),\n",
       " (11, 'Apache'),\n",
       " (10, 'of'),\n",
       " (9, 'collaboration'),\n",
       " (8, 'the'),\n",
       " (7, 'support'),\n",
       " (6, '\\nto'),\n",
       " (5, 'order'),\n",
       " (4, 'in'),\n",
       " (3, 'released'),\n",
       " (2, 'been'),\n",
       " (1, 'has'),\n",
       " (0, 'PySpark')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ord_rdd = spark.sparkContext.parallelize(word_list_ord)\n",
    "word_ord_rdd.sortByKey(False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fc4b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [1,5,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85b93475",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.sparkContext.parallelize(num_list).reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b41c84f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4b47847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c6d66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [59, 57.2, 53.6, 55.4, 51.8, 53.6, 55.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e6a8e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.0,\n",
       " 14.000000000000002,\n",
       " 12.000000000000002,\n",
       " 13.0,\n",
       " 10.999999999999998,\n",
       " 12.000000000000002,\n",
       " 13.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.parallelize(temp).map(lambda x: (x-32)*(5/9)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f216dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.0, 14.000000000000002, 13.0, 13.0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.parallelize(temp).map(lambda x: (x-32)*(5/9)).filter(lambda x: x>=13).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca0139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
